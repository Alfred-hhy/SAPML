from Compiler.script_utils import output_utils

from Compiler.script_utils.data import data
from Compiler.script_utils.data import AbstractInputLoader


from Compiler import ml
from Compiler import library

from Compiler.script_utils.audit import shap

from Compiler.script_utils import config, timers, input_consistency




class TrainingConfig(config.BaseAuditModel):
    n_epochs: int = 1 # -1 = all

    n_s_bert: int = 500

program.options_from_args()
cfg = config.from_program_args(program.args, TrainingConfig)

MultiArray.disable_index_checks()
Array.check_indices = False

if not cfg.emulate:
    pass
program.use_trunc_pr = cfg.trunc_pr

sfix.round_nearest = cfg.round_nearest

ml.set_n_threads(cfg.n_threads)
ml.Layer.back_batch_size = cfg.batch_size
ml.Layer.debug_bert_output = cfg.debug

library.start_timer(timer_id=timers.TIMER_LOAD_DATA)
input_shape_size = cfg.batch_size * cfg.n_batches if cfg.n_batches > 0 else None
input_loader: AbstractInputLoader = data.get_input_loader(dataset=cfg.dataset, audit_trigger_idx=cfg.audit_trigger_idx,
                                                                    batch_size=cfg.batch_size, debug=cfg.debug, emulate=cfg.emulate, consistency_check=cfg.consistency_check, sha3_approx_factor=cfg.sha3_approx_factor,
                                                          load_model_weights=False, input_shape_size=input_shape_size, n_train_samples_bert=cfg.n_s_bert
                                                          )
library.stop_timer(timer_id=timers.TIMER_LOAD_DATA)


library.start_timer(timer_id=timers.TIMER_TRAINING)


train_samples, train_labels = input_loader.train_dataset() # train dataset in case we dont have test dataset

print(train_samples.sizes, "TRAIN")
model = input_loader.model()
model.summary()

model.reset()

if cfg.n_batches > 0:
    train_samples = train_samples.get_part(0, cfg.n_batches * cfg.batch_size)
    print("Train_samples", train_samples, train_samples)
    train_labels = train_labels.get_part(0, cfg.n_batches * cfg.batch_size)
    print("Running on", len(train_samples), "samples")
    model.layers[-1].Y = train_labels
    model.layers[0].X = train_samples
    print(model.layers[0])
    # model.layers[0].N = cfg.n_batches * cfg.batch_size
else:
    model.layers[-1].Y.address = train_labels.address
    model.layers[0].X.address = train_samples.address

print(model.layers)

program.args.append('no_loss')

model.layers[-1].compute_loss = False


model.set_learning_rate(0.001)

if cfg.n_epochs == 0:
    print("Skipping training because n_epochs=0")
else:
    model.run(batch_size=cfg.batch_size)

library.stop_timer(timer_id=timers.TIMER_TRAINING)

library.start_timer(timer_id=timers.TIMER_OUTPUT_COMMIT)

model_layers = AbstractInputLoader._extract_model_weights(model)

output_object = input_consistency.InputObject(model=model_layers)
input_consistency.output(output_object, cfg.consistency_check, cfg.n_threads, cfg.sha3_approx_factor, cfg.cerebro_output_approx_factor)

library.stop_timer(timer_id=timers.TIMER_OUTPUT_COMMIT)

